{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# requirements.txt\n",
    "\n",
    "pip install keras==2.2.3 scikit-learn==0.19.0 tensorflow-gpu==1.15.0\n",
    "\n",
    "pydot  if you have graphdot\n",
    "\n",
    "source code is from https://github.com/smousavi05/Unsupervised_Deep_Learning\n",
    "\n",
    "the file is from https://github.com/smousavi05/Unsupervised_Deep_Learning/blob/master/unsupervised_deep_learning.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from scipy import signal\n",
    "import tensorflow.keras\n",
    "from scipy.signal import butter, lfilter\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, MaxPooling1D, UpSampling1D, Flatten, Dropout, Reshape \n",
    "from keras.layers import Bidirectional, BatchNormalization, ZeroPadding1D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import regularizers\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import idac_metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(30)   # disable the deprecated warning from tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data in original paper\n",
    "\n",
    "x = np.load('x.np.npy') # STFT of local and teleseismic waveforms\n",
    "y = np.load('y.np.npy') # labels\n",
    "n_clusters = 2\n",
    "\n",
    "the shape is (size, 16, 48, 1)\n",
    "\n",
    "Next, we will read our data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "train_data = loadmat('earthb.mat')\n",
    "all_data = train_data['images']\n",
    "all_target = train_data['labels']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_clusters = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data_utils import get_data\n",
    "\n",
    "\n",
    "data = get_data(all_data, all_target, dataset='eq', seed=1, shape=[-1, 40, 40, 1], select=[100, 1700], norm=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test, splits, splits_test = data\n",
    "print('data shape %s' % str(x_train.shape) + str(x_valid.shape) + str(x_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building the autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inp = Input(shape=(40, 40, 1))  \n",
    "e = Conv2D(4, (3, 3), activation='tanh', padding='same')(inp)\n",
    "e = MaxPooling2D((2, 2), padding='same')(e)\n",
    "e = Conv2D(2, (3, 3), activation='tanh', padding='same')(e)\n",
    "e = MaxPooling2D((2, 2), padding='same')(e)\n",
    "e = Conv2D(1, (3, 3), activation='tanh', padding='same')(e)\n",
    "e = MaxPooling2D((2, 2), padding='same')(e)\n",
    "\n",
    "shape_before_flattening = K.int_shape(e)\n",
    "encoded = Flatten()(e)\n",
    "d = Reshape(shape_before_flattening[1:])(encoded)\n",
    "\n",
    "d = Conv2D(1, (3, 3), activation='tanh', padding='same')(d)\n",
    "d = UpSampling2D((2, 2))(d)\n",
    "d = Conv2D(2, (3, 3), activation='tanh', padding='same')(d)\n",
    "d = UpSampling2D((2, 2))(d)\n",
    "d = Conv2D(4, (3, 3), activation='tanh', padding='same')(d)\n",
    "d = UpSampling2D((2, 2))(d)\n",
    "decoded = Conv2D(1, (3, 3), padding='same')(d)\n",
    "\n",
    "autoencoder = Model(inputs=inp, outputs=decoded, name='autoencoder')\n",
    "encoder = Model(inputs=inp, outputs=encoded, name='encoder')\n",
    "#autoencoder.summary()\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(autoencoder, to_file='autoencoder.png', show_shapes=True)\n",
    "# from IPython.display import Image\n",
    "# Image(filename='autoencoder.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretraining of the autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "csv_logger = CSVLogger('pretrain_log.csv')\n",
    "\n",
    "autoencoder.fit(x_train, x_train, batch_size=128, epochs=50, callbacks=[csv_logger])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now, adding the clustering layer into the bottelneck layer "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### clustering layers\n",
    "class ClusteringLayer(Layer):\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight((self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) \n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "print('...Finetuning...')   \n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "model = Model(inputs=encoder.input, outputs=[clustering_layer, autoencoder.output])\n",
    "model.compile(loss=['kld', 'mse'], loss_weights=[0.1, 1], optimizer='adam')\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png', show_shapes=True)\n",
    "# from IPython.display import Image\n",
    "# Image(filename='model.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finetuning of full network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### initializing the weights using Kmean and assigning them to the model\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(x_train))\n",
    "y_pred_last = np.copy(y_pred)\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics.acc(y_train, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "## parameters for the finetuning\n",
    "batch_size = 128\n",
    "tol = 0.001 # tolerance threshold to stop training\n",
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 10000\n",
    "update_interval = int(x_train.shape[0] / batch_size) + 1\n",
    "index_array = np.arange(x_train.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "### simultaneous optimization and clustering\n",
    "def target_distribution(q):\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.T / weight.sum(1)).T\n",
    "\n",
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q, _  = model.predict(x_train, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p       \n",
    "        y_pred = q.argmax(1) # evaluate the clustering performance\n",
    "\n",
    "        if y_train is not None:\n",
    "            acc = np.round(metrics.acc(y_train, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d(Epoch %d): acc = %.5f' % (ite, ite // update_interval, acc), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            break\n",
    "        \n",
    "        IN = encoder.predict(x_train)        \n",
    "    \n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, x_train.shape[0])]\n",
    "    loss = model.train_on_batch(x=x_train[idx], y=[p[idx], x_train[idx]])\n",
    "    index = index + 1 if (index + 1) * batch_size <= x_train.shape[0] else 0  \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc = encoder.predict(x_train[:3000])   # the data is large, TSNE is slow, so use a small subset\n",
    "print('Get features, then TSNE')\n",
    "from sklearn.manifold import TSNE\n",
    "redu = TSNE(random_state=123).fit_transform(enc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plotter(S, y, target_names):\n",
    "    '''\n",
    "    function to visualize the outputs of t-SNE\n",
    "    '''\n",
    "    # choose a color palette with seaborn.\n",
    "    colors = ['navy', 'turquoise', 'darkorange']\n",
    "    lw = 2\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(22, 10))\n",
    "    ax = f.add_subplot(111)\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "        plt.scatter(S[y == i, 0], S[y == i, 1], color=color, alpha=.5, lw=lw, s=100, label=target_name)\n",
    "    plt.legend(loc='lower left', shadow=False, scatterpoints=1, prop={'size': 20})\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight') \n",
    "    plt.show()\n",
    "\n",
    "    return f, ax\n",
    "\n",
    "\n",
    "target_names = ['a', 'b', 'c']\n",
    "plotter(redu, y_train[:3000], target_names) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}